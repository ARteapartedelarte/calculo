---
title: "Tema 5 - Derivabilidad de funciones"
author: "Juan Gabriel Gomila, Arnau Mir y Llorenç Valverde"
date: ''
output: 
  ioslides_presentation:
    widescreen: true
    css: Mery_style.css
    logo: Images/calculus.gif
    fig_caption: yes
---
<script src="https://kit.fontawesome.com/a0edb659c7.js" crossorigin="anonymous"></script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
reticulate::use_python("/Users/juangabriel/anaconda3/bin/python")
#reticulate::py_install("sympy")
```

# Derivada de una función en un valor del dominio de la misma

## Introducción
La derivada de una función nace de formalizar la noción de **recta tangente** en un valor $x_0$ para una función $f(x)$.

En el gráfico siguiente, podemos observar un ejemplo del dibujo de una función junto con la recta tangente en un punto $x_0$ de su dominio.

La pendiente de la recta tangente (en rojo) vendría a representar lo que denominaremos la derivada de la función $f(x)$ en $x=x_0$.

## Introducción
```{r,echo=FALSE,fig.align='center'}
x=seq(from=-1,to=pi, by=0.01)
f = function(x){sin(x)+cos(x)}
plot(x,f(x),type="l")
x0=0
text(x0+0.15,f(x0)-0.175,expression(paste("(",x[0],",f(",x[0],"))")))
points(x0,f(x0),pch=19,col="blue")
m=cos(x0)-sin(x0)
abline(f(x0)-m*x0,m,col="red")
```

## Introducción

<div class="center">

```{r, echo=FALSE, label=der1,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Derivada1.png",dpi=1200)
```
</div>


## Definición de derivada de una función en un punto

Consideremos la figura anterior.

La pendiente de una recta recordemos que se define como la tangente del ángulo con el eje X. 

Hemos dibujado una función $f(x)$ que pasa por el punto $(x_0,f(x_0))$ junto con una recta secante que pasa por el punto. 

Otro punto de dicha recta dado un valor $h$ sería $(x_0+h,f(x_0+h))$. Intuitivamente dicha recta secante "tiende" a la tangente cuando el valor $h$ tiende a cero. 

## Definición de derivada de una función en un punto

La pendiente de la recta secante como puede observarse es la tangente del ángulo $\alpha$ que vale $\frac{f(x_0+h)-f(x_0)}{h}$.
Entonces, la definición de derivada de $f(x)$ en $x=x_0$ es la siguiente:

<l class="definition"> Definición de derivada en un punto </l>
Sea $f:(a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$. Diremos que $f$ es **derivable** en $x_0$ o que **existe la derivada de $f$ en $x_0$** cuando existe el límite siguiente:
$$
\lim_{h\to 0}\frac{f(x_0+h)-f(x_0)}{h},
$$
y, en caso en que exista, llamaremos a dicho límite **derivada de la función $f$ en $x_0$** escrita matemáticamente como $f'(x_0)$.

## Definición de derivada de una función en un punto
<l class="observ">Observación: </l>
la derivada de una función es un propiedad **local**, es decir, está definida en un punto $x_0$ del dominio.

Cuando, haciendo un abuso del lenguaje, se dice que la función $f$ es **derivable**, se quiere decir que dicha función es derivable en todos los puntos del dominio de la misma.

## Definición de derivada de una función en un punto

<l class="observ">Observación: </l>
La derivada de una función $f$ en un punto de su dominio $x_0$ se puede expresar también de la forma siguiente:
$$
\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}.
$$
Para ver la expresión anterior, basta considerar el cambio de variable siguiente $x=x_0+h$, de donde $h=x-x_0$ y aplicar la definición de derivada.

Fijaos que decir que $h$ tiende a cero es equivalente a decir que $x$ tiende a $x_0$.


## Ejemplos
<div class="example">
**Derivada de la función constante**

Veamos que si la función $f$ es constante en todo su dominio, $f(x)=k$, para todo $x$ del dominio, la derivada de $f$ en cualquier punto del mismo es nula.

Sea $x_0$ un punto del dominio de $f$. La **derivada** de $f$ en $x_0$ será:
$$
f'(x_0)=\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{k-k}{x-x_0}=\lim_{x\to x_0} 0 =0.
$$

</div>


<div class="example">
**Derivada del monomio de grado $n$**

Calculemos la derivada de función $f$ si ésta vale $f(x)=x^n$, donde $n$ es un valor natural mayor que $1$ ($n=1,2,\ldots$):

Sea $x_0$ un punto del dominio de $f$. La **derivada** de $f$ en $x_0$ será:
$$
\begin{array}{rl}
f'(x_0) & =\displaystyle\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{x^n-x_0^n}{x-x_0}=\lim_{x\to x_0} \frac{(x-x_0)(x^{n-1}+x^{n-2}x_0+x^{n-3}x_0^2+\cdots+ x_0^{n-1})}{x-x_0} \\ & \displaystyle =\lim_{x\to x_0} x^{n-1}+x^{n-2}x_0+x^{n-3}x_0^2+\cdots+ x_0^{n-1} =n\cdot x_0^{n-1}.
\end{array}
$$
</div>

## Ejemplo
<div class="example">
**Derivada del monomio de grado $n$**

La derivada de la función anterior en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=derivative+of+x%5En)
</l>

</div>


## Ejemplos
<div class="example">
**Derivada del valor absoluto**

Consideremos la función $f(x)=|x|$, valor absoluto de $x$, definida en todo $\mathbb{R}$ como:
$f(x)=\begin{cases}
x, & \mbox{si } x\geq 0, \\
-x & \mbox{si }x<0.
\end{cases}$

Estudiemos la derivabilidad de $f$ en $x_0=0$, es decir, veamos si el límite siguiente existe:
$\displaystyle\lim_{x\to 0}\frac{f(x)-f(0)}{x-0}=\lim_{x\to 0}\frac{|x|}{x}$.

Si hacemos el límite anterior por la derecha o para los valores $x>0$, obtenemos:
$$
\lim_{x\to 0^+}\frac{|x|}{x}=\lim_{x\to 0^+}\frac{x}{x}=\lim_{x\to 0^+}1 =1.
$$
En cambio, si lo hacemos por la izquierda o para los valores $x<0$, obtenemos:
$$
\lim_{x\to 0^-}\frac{|x|}{x}=\lim_{x\to 0^-}\frac{-x}{x}=\lim_{x\to 0^-} -1 =-1.
$$

</div>

## Ejemplos
<div class="example">
**Derivada del valor absoluto**

Como los límites anteriores no coinciden, concluimos que el límite $\displaystyle \lim_{x\to 0}\frac{|x|}{x}$ no existe y por tanto, $f$ no es derivable en $x=0$.

Gráficamente se observa que la función anterior tiene una punta en $x=0$ y, por tanto, $f$ no puede ser derivable en dicho punto.

Este comportamiento es el usual cuando una función no es derivable en un punto $x_0$, es decir, se observa gráficamente que en dicho punto, la función no tiene un comportamiento suave.

</div>

## Ejemplos
<div class="example">
**Derivada del valor absoluto**
```{r,echo=FALSE,fig.align='center'}
x=seq(from=-1,to=1,by=0.01)
plot(x,abs(x),type='l',ylab=expression("|x|"),main="Gráfica de función valor absoluto")
```


</div>

## Ejemplo
<div class="example">
**Derivada del valor absoluto**

La gráfica del valor absoluto en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=plot+of+%7Cx%7C)
</l>

</div>

# Propiedades de las funciones derivables

## Derivabilidad implica continuidad

<l class="prop"> Teorema:</l> sea $f$ una función real de variable real y sea $x_0$ un valor del dominio de $f$. Si $f$ es derivable en $x_0$, entonces $f$ es continua en $x_0$.


## Derivabilidad implica continuidad
<div class="dem">
**Demostración.**

Definimos la función siguiente en un entorno de valor $x_0$:
$$
g(x)=\begin{cases}
\frac{f(x)-f(x_0)}{x-x_0}, & \mbox{si }x\neq x_0,\\
f'(x_0), & \mbox{si } x=x_0.
\end{cases}
$$
Usando que $f$ es derivable en $x_0$, tenemos que la función $g$ definida anteriormente será continua en $x_0$ ya que:
$$
\lim_{x\to x_0} g(x)=\lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}=f'(x_0)=g(x_0).
$$
Si despejamos $f(x)$ de la expresión de $g(x)$ obtenemos $f(x)=f(x_0)+g(x)\cdot (x-x_0)$. 

Veamos que $f$ es continua en $x_0$:
$$
\lim_{x\to x_0}f(x)=\lim_{x\to x_0} f(x_0)+g(x)\cdot (x-x_0) = f(x_0)+f'(x_0)\cdot 0 = f(x_0),
$$
tal como queríamos ver.
</div>


## La derivada de la suma es suma de derivadas
<l class="prop">Proposición.</l>
Sean $f$ y $g$ dos funciones reales de variable real y sea $x_0$ un valor del dominio de $f$ y de $g$. Si $f$ y $g$ son derivables en $x_0$, también lo es la función suma $f+g$, y se verifica que: $(f+g)'(x_0)=f'(x_0)+g'(x_0)$.

<div class="dem">
**Demostración:**
$$
\begin{array}{rl}
(f+g)'(x_0) & = \displaystyle\lim_{x\to x_0}\frac{(f+g)(x)-(f+g)(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{f(x)+g(x)-f(x_0)-g(x_0)}{x-x_0} \\ & = \displaystyle \lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0} + \lim_{x\to x_0}\frac{g(x)-g(x_0)}{x-x_0}=f'(x_0)+g'(x_0).
\end{array}
$$

</div>

## La derivada de una función por una constante es la constante por la derivada de la función
<l class="prop">Proposición.</l>
Sea $k\in\mathbb{R}$ un valor real, $f$ una función real de variable real y $x_0$ un valor del dominio de $f$. Entonce si $f$ es derivable en $x_0$, también lo es $k\cdot f$ y se verifica que: $(k\cdot f)'(x_0)=k\cdot f'(x_0)$.

<div class="dem">
**Demostración:**

$$
\begin{array}{rl}
(k\cdot f)'(x_0) & \displaystyle =\lim_{x\to x_0}\frac{(k\cdot f)(x)-(k\cdot f)(x_0)}{x-x_0}=
\lim_{x\to x_0}\frac{k\cdot f(x)-k\cdot f(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{k\cdot (f(x)-f(x_0))}{x-x_0} \\  &\displaystyle =k\lim_{x\to x_0}\frac{ f(x)-f(x_0)}{x-x_0}=k f'(x_0).
\end{array}
$$
</div>

## La derivada del producto de funciones
<l class="prop">Proposición.</l>
Sean $f$ y $g$ dos funciones reales de variable real y sea $x_0$ un valor del dominio de $f$ y de $g$. Si $f$ y $g$ son derivables en $x_0$, también lo es la función producto $f\cdot g$, y se verifica que: $(f\cdot g)'(x_0)=f'(x_0)\cdot g(x_0)+f(x_0)\cdot g'(x_0)$.

<div class="dem">
**Demostración:**
$$
\begin{array}{rl}
(f\cdot g)'(x_0) & = \displaystyle\lim_{x\to x_0}\frac{(f\cdot g)(x)-(f\cdot g)(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{f(x)\cdot g(x)-f(x_0)\cdot g(x_0)}{x-x_0} \\ & = \displaystyle \lim_{x\to x_0}\frac{f(x)\cdot g(x)-f(x)\cdot g(x_0)+f(x)\cdot g(x_0)-f(x_0)\cdot g(x_0)}{x-x_0}\\ & = \displaystyle \lim_{x\to x_0}\frac{f(x)\cdot (g(x)- g(x_0))+(f(x)-f(x_0))\cdot g(x_0)}{x-x_0}\\ & = \displaystyle \lim_{x\to x_0}f(x)\cdot\frac{g(x)- g(x_0)}{x-x_0}+\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}\cdot g(x_0)=f(x_0)\cdot g'(x_0)+f'(x_0)\cdot g(x_0).
\end{array}
$$

</div>

## La derivada del cociente de funciones
<l class="prop">Proposición.</l>
Sean $f$ y $g$ dos funciones reales de variable real y sea $x_0$ un valor del dominio de $f$ y de $g$ tal que $g'(x_0)\neq 0$. Si $f$ y $g$ son derivables en $x_0$, también lo es la función cociente $\frac{f}{g}$, y se verifica que: $\left(\frac{f}{g}\right)'(x_0)=\frac{f'(x_0)\cdot g(x_0)-f(x_0)\cdot g'(x_0)}{g(x_0)^2}$.

<div class="dem">
**Demostración:**
$$
\begin{array}{rl}
\left(\frac{f}{g}\right)'(x_0) & = \displaystyle\lim_{x\to x_0}\frac{\left(\frac{f}{g}\right)(x)-\left(\frac{f}{g}\right)(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{\frac{f(x)}{g(x)}-\frac{f(x_0)}{g(x_0)}}{x-x_0} =\lim_{x\to x_0} \frac{f(x)\cdot g(x_0)-g(x)\cdot f(x_0)}{g(x)\cdot g(x_0)\cdot (x-x_0)}  \\ & \displaystyle =\lim_{x\to x_0} \frac{f(x)\cdot g(x_0)-f(x_0)\cdot g(x_0)+f(x_0)\cdot g(x_0) -g(x)\cdot f(x_0)}{g(x)\cdot g(x_0)\cdot (x-x_0)} \\ & = \displaystyle \lim_{x\to x_0}\frac{1}{g(x)\cdot g(x_0)}\cdot \left(\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}\cdot g(x_0)-f(x_0)\cdot \lim_{x\to x_0} \frac{g(x)-g(x_0)}{x-x_0}\right) \\ & = \displaystyle \frac{1}{g(x_0)^2}(f'(x_0)\cdot g(x_0)-f(x_0)\cdot g'(x_0)).
\end{array}
$$

</div>


## Derivada de la función inversa
<l class="prop">Proposición.</l>
Sea $f$ una función real de variable real y $x_0$ un valor del dominio de $f$. Suponemos que $f$ es derivable en $x_0$ y que $f'(x_0)\neq 0$. Supongamos que $f$ admite inversa $g$, es decir, existe una función $g$ tal que $g\circ f=\mathrm{Id}$, es decir, para cualquier valor $x$ del dominio de $f$, se cumple que $g(f(x))=x$. Además, suponemos que $g$ es continua en $f(x_0)$. Entonces $g$ es derivable en $f(x_0)$ y se verifica que $g'(f(x_0))=\frac{1}{f'(x_0)}$.

## Derivada de la función inversa
<div class="dem">
**Demostración:**

El valor de $g'(f(x_0))$ es:
$g'(f(x_0))  = \displaystyle\lim_{y\to f(x_0)}\frac{g(y)-g(f(x_0))}{y-f(x_0)}.$

Para el cálculo del límite anterior, hacemos el cambio de variable siguiente: $y=f(x)$, o $x=g(y)$. Como $y$ tiende a $f(x_0)$, tendremos con la variable nueva que $f(x)$ tiende a $f(x_0)$ pero como $g$ es continua en $f(x_0)$, deducimos que $g(f(x))=x$ tiende a $g(f(x_0))=x_0$. En resumen, el límite anterior puede escribirse como:
$$
g'(f(x_0)) =\lim_{x\to x_0}\frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)}=\lim_{x\to x_0}\frac{x-x_0}{f(x)-f(x_0)} = \frac{1}{\displaystyle\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}}=\frac{1}{f'(x_0)}.
$$

</div>

## Ejemplo
<div class="example">
**Ejemplo: derivada de la función $g(x)=\sqrt[n]{x}$.**

La función $g(x)=\sqrt[n]{x}$ es la inversa de la función $f(x)=x^n$ ya que:
$g(f(x))=g(x^n)=\sqrt[n]{x^n}=x$. 

Usando la expresión vista anteriormente, podemos escribir que: $g'(f(x))=g'(x^n)=\frac{1}{f'(x)}$.

En un ejemplo anterior vimos que $f'(x)=n\cdot x^{n-1}$. Por tanto:  $g'(x^n)=\frac{1}{n\cdot x^{n-1}}$.

Sea $y=x^n$, entonces $x=\sqrt[n]{y}$. Por tanto, $g'(y)=\frac{1}{n\cdot x^{n-1}}=\frac{1}{n\cdot \sqrt[n]{y^{n-1}}}$.


La derivada de la función $g(x)$ en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=derivative+of+x%5E%281%2Fn%29)
</l>

</div>


## Ejemplo
<div class="example">
**Ejemplo: derivada de la función $\tan x$.**

La función $\tan x$ está definida como $\frac{\sin x}{\cos x}$.

Calculemos primero la derivada de la función $\sin x$ en un valor $x_0$:
$$
\begin{array}{rl}
(\sin)'(x_0) & \displaystyle =\lim_{x\to x_0}\frac{\sin x-\sin x_0}{x-x_0}=\lim_{x\to x_0}\frac{2\cos\left(\frac{x+x_0}{2}\right)\cdot\sin\left(\frac{x-x_0}{2}\right)}{x-x_0}=2\cdot \cos(x_0)\lim_{x\to x_0}\frac{\sin\left(\frac{x-x_0}{2}\right)}{x-x_0} \\ & \displaystyle = \cos(x_0)\lim_{x\to x_0}\frac{\sin\left(\frac{x-x_0}{2}\right)}{\frac{x-x_0}{2}} = \cos(x_0),
\end{array}
$$
usando que $\lim\limits_{x\to x_0}\frac{\sin\left(\frac{x-x_0}{2}\right)}{\frac{x-x_0}{2}}=1.$ La expresión anterior se deduce del hecho de que $\lim\limits_{t\to 0} \frac{\sin t}{t}=1$. 

Si se hace el cambio de variable $t=\frac{x-x_0}{2}$ y teniendo en cuenta que como $x\to x_0$, entonces $t\to 0$, los dos límites anteriores son iguales a 1.


</div>

## Ejemplo
<div class="example">
**Ejemplo: derivada de la función $\tan x$.**

Para calcular la derivada de la función $\cos x$, usamos una técnica similar:
$$
\begin{array}{rl}
(\cos)'(x_0) & \displaystyle =\lim_{x\to x_0}\frac{\cos x-\cos x_0}{x-x_0}=\lim_{x\to x_0}\frac{-2\sin\left(\frac{x+x_0}{2}\right)\cdot\sin\left(\frac{x-x_0}{2}\right)}{x-x_0}=-2\cdot \sin(x_0)\lim_{x\to x_0}\frac{\sin\left(\frac{x-x_0}{2}\right)}{x-x_0} \\ & \displaystyle =- \sin(x_0)\lim_{x\to x_0}\frac{\sin\left(\frac{x-x_0}{2}\right)}{\frac{x-x_0}{2}} = -\sin(x_0).
\end{array}
$$
Usamos la propiedad de la derivada del cociente, podemos hallar la derivada de la función $\tan x$:
$$
\begin{array}{rl}
(\tan)'(x_0) & =\left(\frac{\sin}{\cos}\right)'(x_0)=\frac{\sin'(x_0)\cdot \cos(x_0)-\sin (x_0)\cdot \cos'(x_0)}{\cos^2(x_0)}=\frac{\cos(x_0)\cdot \cos(x_0)+\sin (x_0)\cdot \sin(x_0)}{\cos^2(x_0)} \\ & =
\frac{\cos^2(x_0)+\sin^2(x_0)}{\cos^2(x_0)}=\frac{1}{\cos^2 (x_0)}=1+\tan^2 (x_0).
\end{array}
$$


La derivada de la función $\tan x$ en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=derivative+of+tan%28x%29)
</l>

</div>

##  Derivada de la función compuesta. Regla de la cadena
<l class="prop">Proposición.</l>
Sean $f$ y $g$ dos funciones reales de variable real. Sea $x_0$ un valor del dominio de $f$ tal que $f(x_0)$ es del dominio de $g$. Supongamos que $g$ es derivable en $f(x_0)$ y $f$ es derivable en $x_0$. Entonces la función compuesta $g\circ f$ es derivable en $x_0$ y se verifica que:
$(g\circ f)'(x_0)=g'(f(x_0))\cdot f'(x_0)$. 


##  Derivada de la función compuesta. Regla de la cadena

<div class="dem">
**Demostración:**
$$
\begin{array}{rl}
(g\circ f)'(x_0) & \displaystyle =\lim_{x\to x_0}\frac{(g\circ f)(x)-(g\circ f)(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{g(f(x))-g(f(x_0))}{x-x_0} \\ & \displaystyle =\lim_{x\to x_0}\frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)}\cdot \lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}=g'(f(x_0))\cdot f'(x_0).
\end{array}
$$
En el último cálculo, podemos afirmar que el límite $\displaystyle\lim_{x\to x_0}\frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)}$ vale $g'(f(x_0))$ porque como $f$ es derivable en $x_0$, $f$ será continua en $x_0$ y si $x\to x_0$, entonces $f(x)\to f(x_0)$ y el límite anterior queda:
$$
\lim_{x\to x_0}\frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)} =\lim_{f(x)\to f(x_0)}\frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)}=g'(f(x_0)).
$$

</div>

## Ejemplo
<div class="example">
**Ejemplo**

Hallemos la derivada de la función $h(x)=\arctan (x^3+x^2+1)$.

La función anterior es la composición de la función $f(x)=x^3+x^2+1$ y $g(y)=\arctan y$, es decir:
$h(x)=(g\circ f)(x)$.

La derivada de la función $f(x)$ se puede calcular usando la propiedad de la suma de derivadas y la expresión de la derivada del monomio $x^n$:
$$
(x^3+x^2+1)'=(x^3)'+(x^2)'+(1)' = 3x^2+2x+0=3x^2+2x.
$$

A continuación, hallemos la derivada de la función $g(y)=\arctan y$. Dicha función es la función inversa de la función $\tan x$.
Usando la expresión de la derivada de la función inversa, tenemos:
$$
g'(\tan x)=\frac{1}{\tan'(x)}=\frac{1}{\frac{1}{\cos^2 x}}=\cos^2 x.
$$

</div>

## Ejemplo
<div class="example">
**Ejemplo**

Para hallar $g'(y)$, tenemos que escribir $y=\tan x$, y, por tanto, $x=\arctan y$:
$$
g'(y)=\cos^2(\arctan y)=\frac{1}{1+\tan^2 (\arctan y)}=\frac{1}{1+y^2},
$$
donde hemos usado la siguiente relación trigonométrica: $\cos^2\alpha = \frac{1}{1+\tan^2\alpha}$.

La derivada de la función $h(x)$ usando la **regla de la cadena** será:
$$
\begin{array}{rl}
h'(x) & =(g\circ f)'(x)=g'(f(x))\cdot f'(x)=\frac{1}{1+f(x)^2}\cdot (3 x^2+2x)=\frac{3x^2+2x}{1+(x^3+x^2+1)^2}\\ & =\frac{3x^2+2x}{x^6+2 x^5+x^4+2 x^3+2 x^2+2}.
\end{array}
$$


La derivada de la función $h(x)$ en `Wolfram Alpha` se muestra en el enlace siguiente: <l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=derivative+of+arctan%28x%5E3%2Bx%5E2%2B1%29)
</l>
</div>

## Tablas de derivadas

Si vais a [tablas de derivadas](https://www.google.com/search?tbm=isch&sxsrf=ACYBGNQqojnjJv8BaCiJGV99iyRexZsPcg%3A1578831703469&source=hp&biw=2560&bih=1268&ei=Vw8bXsXVGoKkgweJ7qO4Bw&q=tablas+de+derivadas&oq=tablas+de+der&gs_l=img.3.0.35i39j0l5j0i5i30l4.5860.8647..10003...2.0..0.70.862.13......0....1..gws-wiz-img.....10..35i362i39j0i131.bUJ_Ou6rWlA) y escribís "tablas de derivadas" en la casilla de búsqueda, encontraréis un montón de tablas de derivadas para las funciones más usadas.


# Teoremas de derivación

## Relación de la derivación con los extremos relativos de una función

<l class="definition"> Definición de máximo relativo de una función.</l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Diremos que $f$ tiene un **máximo relativo** en el punto $x_0$ si existe un entorno de $x_0$, es decir, existe un valor $\delta >0$, tal que para todo valor $x$ de este entorno, es decir, $x\in (x_0-\delta,x_0+\delta)\subseteq (a,b)$, se cumple que $f(x)\leq f(x_0)$. Si la condición anterior se verifica para cualquier valor $x\in (a,b)$, diremos que $f$ tiene un **máximo absoluto** en el punto $x_0$.

## Relación de la derivación con los extremos relativos de una función
<l class="definition"> Definición de mínimo relativo de una función.</l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Diremos que $f$ tiene un **mínimo relativo** en el punto $x_0$ si existe un entorno de $x_0$, es decir, existe un valor $\delta >0$, tal que para todo valor $x$ de este entorno, es decir, $x\in (x_0-\delta,x_0+\delta)\subseteq (a,b)$, se cumple que $f(x)\geq f(x_0)$. Si la condición anterior se verifica para cualquier valor $x\in (a,b)$, diremos que $f$ tiene un **mínimo absoluto** en el punto $x_0$.

Los puntos donde $f$ presente un **máximo** o un **mínimo** **relativos** o **absolutos** se denominan **extremos relativos** o **absolutos** de la función.

## Ejemplo
<div class="example">
**Ejemplo**

Consideremos la función siguiente definida en el intervalo $(-2\pi,2\pi)$: 
$$
\begin{array}{rl}
f:(-2\pi,2\pi) & \longrightarrow \mathbb{R},\\
 x& \longrightarrow \sin(x)-\cos(x).
\end{array}
$$
El gráfico de dicha función puede observase en la figura siguiente.

Vemos que tiene dos **máximos relativos** en los valores $x=-\frac{5}{4}\pi$ y $x=\frac{3}{4}\pi$ y dos **mínimos relativos** en los valores $x=-\frac{\pi}{4}$ y $x=\frac{7}{4}\pi$. 

Observamos que dichos máximos y mínimos son **absolutos**.

El gráfico de la función anterior puede verse en `Wolfram Alpha` en el enlace siguiente: <l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=plot+of+sin%28x%29-cos%28x%29%2C+where++x+is+between+-2+pi+and+2+pi)
</l>
</div>


## Ejemplo
<div class="example">
```{r,echo=FALSE,fig.align='center'}
xmin=-2*pi
xmax=2*pi
ymin=-1.5
ymax=1.5
tolx=0.01*(xmax-xmin)
toly=0.05*(ymax-ymin)
quantsx=8
quantsy=6
f = function(x){sin(x)-cos(x)}
plot(c(xmin-tolx,xmax+tolx,xmin-tolx,xmax+tolx),c(ymin-toly,ymin-toly,ymax+toly,ymax+toly),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
x=seq(from=xmin,to=xmax,by=0.01)
#points(x,f(x),type="l")
lines(c(0,0),c(ymin,ymax))
lines(c(xmin,xmax),c(0,0))
text(xmax-3*tolx,-2*tolx,"x")
text(toly,ymax+toly/2,"y")
for (i in 0:(quantsx)){
  lines(rep(xmin+((xmax-xmin)/quantsx)*i,2),c(-0.5*toly,+0.5*toly))
  ii=-2+0.5*i}
text(xmin+((xmax-xmin)/quantsx)*0,-1.5*toly,expression(-2*pi),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*1,-2.5*toly,expression(-frac(3,2)*pi),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*2,-1.5*toly,expression(-pi),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*3,-2.5*toly,expression(-frac(pi,2)),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*4+0.1,-1.5*toly,0,cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*5,-2.5*toly,expression(frac(pi,2)),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*6,-1.5*toly,expression(pi),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*7,-2.5*toly,expression(frac(3,2)*pi),cex=0.75)
text(xmin+((xmax-xmin)/quantsx)*8,-1.5*toly,expression(2*pi),cex=0.75)

lines(rep(xmin+((xmax-xmin)/quantsx)*1.5,2),c(-0.5*toly,+0.5*toly))
lines(c(-5*pi/4,-5*pi/4),c(0,f(-5*pi/4)),lty=2,col="blue")
text(xmin+((xmax-xmin)/quantsx)*1.5,-2.5*toly,expression(-frac(5,4)*pi),cex=0.75)

lines(rep(xmin+((xmax-xmin)/quantsx)*3.5,2),c(-0.5*toly,+0.5*toly))
lines(c(-pi/4,-pi/4),c(0,f(-pi/4)),lty=2,col="blue")
text(xmin+((xmax-xmin)/quantsx)*3.5,2.5*toly,expression(-frac(pi,4)),cex=0.75)

lines(rep(xmin+((xmax-xmin)/quantsx)*5.5,2),c(-0.5*toly,+0.5*toly))
lines(c(3*pi/4,3*pi/4),c(0,f(3*pi/4)),lty=2,col="blue")
text(xmin+((xmax-xmin)/quantsx)*5.5,-2.5*toly,expression(frac(3,4)*pi),cex=0.75)

lines(rep(xmin+((xmax-xmin)/quantsx)*7.5,2),c(-0.5*toly,+0.5*toly))
lines(c(7*pi/4,7*pi/4),c(0,f(7*pi/4)),lty=2,col="blue")
text(xmin+((xmax-xmin)/quantsx)*7.5,2.5*toly,expression(frac(7,4)*pi),cex=0.75)

for (i in 0:(quantsy)){
  lines(c(-tolx,tolx),ymin+rep(((ymax-ymin)/quantsy)*i,2))
  if (i==3){text(2.5*tolx,0.1+ymin+((ymax-ymin)/quantsy)*3,ymin+((ymax-ymin)/quantsy)*3,cex=0.75)}
  else
    {text(3*tolx,ymin+((ymax-ymin)/quantsy)*i,ymin+((ymax-ymin)/quantsy)*i,cex=0.75)}
  }
lines(x,f(x),col="red")
text(pi,1.3,"f(x)")
```


</div>


## Relación de la derivación con los extremos relativos de una función
<l class="prop">Teorema:</l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$ que sea **extremo relativo** de la función. Entonces si $f$ es **derivable** en el punto $x_0$, se verifica que $f'(x_0)=0$.

Intuitivamente, el teorema anterior nos dice que si la función $f$ tiene un comportamiento **suave** en el extremo $x_0$, la recta tangente en este punto tiene que ser **horizontal**, es decir, su pendiente tiene que ser nula, tal como podemos observar en los extremos del ejemplo anterior. 


## Relación de la derivación con los extremos relativos de una función

<div class="dem">
**Demostración**

Como $f$ es derivable en el punto $x_0$, sabemos que existe el límite siguiente $\displaystyle\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}$.

Decir que $f$ es derivable en $x_0$ es equivalente a decir que la función siguiente:
$$
g(x)=\begin{cases}
\frac{f(x)-f(x_0)}{x-x_0}, & \mbox{si }x\neq x_0,\\
f'(x_0), &\mbox{si }x=x_0,
\end{cases}
$$
es continua en $x_0$.

Veamos a continuación que necesariamente $g(x_0)=f'(x_0)=$ y quedará demostrado el teorema.

Supongamos que $g(x_0)>0$. Como la función $g$ es continua en $x_0$, por el teorema de conservación del signo de funciones continuas, existirá un entorno de $x_0$, es decir, existirá un $\delta >0$ tal que si $x\in (x_0-\delta,x_0+\delta)\subseteq (a,b)$, $g(x)>0$ también será positiva para todos los valores $x$ de dicho entorno.


</div>

## Relación de la derivación con los extremos relativos de una función

<div class="dem">
**Demostración**

Es decir, para todo $x\in (x_0-\delta,x_0+\delta)$, $g(x)=\frac{f(x)-f(x_0)}{x-x_0}>0$.

Esto es equivalente a decir que el numerador y el denominador de la fracción anterior tienen el mismo signo o, dicho en otras palabras:

* si $x\in (x_0-\delta,x_0+\delta)$ y $x>x_0$, entonces $f(x) > f(x_0)$ y,
* si $x\in (x_0-\delta,x_0+\delta)$ y $x<x_0$, entonces $f(x) < f(x_0)$.

Las condiciones anteriores contradicen el hecho que $x_0$ sea un extremo ya que hemos encontrado valores en un entorno del mismo que superan $f(x_0)$ y valores del mismo entorno que son menores que $f(x_0)$. 
En conclusión, llegamos a una contradicción al suponer que $g(x_0)=f'(x_0)>0$.



</div>

<div class="exercise">
**Ejercicio**

Suponer que $g(x_0)=f'(x_0)<0$ y ver que se llega a una contradicción razonando de manera similar.
</div>



## Relación de la derivación con los extremos relativos de una función

<div class="dem">
**Demostración**

Al no poder ser que $f'(x_0)>$ ni $f'(x_0)<0$, necesariamente $f'(x_0)=0$ tal como queríamos demostrar.
</div>

</l class="observ"> Observación: </l> el recíproco del teorema anterior es falso. Es decir, el hecho que $f'(x_0)$ sea 0, no implica que $x_0$ sea un **extremo relativo** de la función.

<div class="example">
**Ejemplo**

Considerar, por ejemplo, la función $f(x)=x^2\cdot \sin(x)$. Si derivamos dicha función, obtenemos:
$$
f'(x)=2x\sin(x)+x^2\cos(x).
$$
Vemos que $f'(0)=0$. En cambio $f$ no tiene ningún extremo en este punto tal como se observa en el gráfico de su función:
</div>



## Relación de la derivación con los extremos relativos de una función
<div class="example">
**Ejemplo**
```{r,echo=FALSE,fig.align='center'}
xmin=-2
xmax=2
ymin=-2.5
ymax=2.5
tolx=0.01*(xmax-xmin)
toly=0.05*(ymax-ymin)
quantsx=4
quantsy=4
f = function(x){x^2*sin(x)}
plot(c(xmin-tolx,xmax+tolx,xmin-tolx,xmax+tolx),c(ymin-toly,ymin-toly,ymax+toly,ymax+toly),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
x=seq(from=xmin,to=xmax,by=0.01)
#points(x,f(x),type="l")
lines(c(0,0),c(ymin,ymax))
lines(c(xmin,xmax),c(0,0))
text(xmax-3*tolx,-3*tolx,"x")
text(toly,ymax+toly/2,"y")
for (i in 0:(quantsx)){
  lines(rep(xmin+((xmax-xmin)/quantsx)*i,2),c(-0.5*toly,+0.5*toly))
  text(xmin+((xmax-xmin)/quantsx)*i,-1*toly,xmin+((xmax-xmin)/quantsx)*i,cex=0.75)}


for (i in 0:(quantsy)){
  lines(c(-tolx,tolx),ymin+rep(((ymax-ymin)/quantsy)*i,2))
  text(3*tolx,ymin+((ymax-ymin)/quantsy)*i,ymin+((ymax-ymin)/quantsy)*i,cex=0.75)
  }
lines(x,f(x),col="red")
text(pi,1.3,"f(x)")
```


</div>

## Relación de la derivación con los extremos relativos de una función
<div class="example">
**Ejemplo**

Para ver que el 0 no es extremo relativo, es facil ver que para $x\in (0,\pi)$, $f(x)\geq 0$ y para $x\in (-\pi,0)$, $f(x)\leq 0$. Comprobémoslo para unos cuantos valores en `python`, para $x=-0.2,-0.1,0.1,0.2$:
```{python}
from sympy import * 
  
def f(x):
 return(x**2*sin(x))
```

</div>

## Relación de la derivación con los extremos relativos de una función
<div class="example">
**Ejemplo**

```{python}
for x in [-0.2,-0.1,0.1,0.2]:
  print('f({x})={res}'.format(x=x, res=f(x)))
```
</div>

## Relación de la derivación con los extremos relativos de una función
<div class="example">
**Ejemplo**

El cálculo de la derivada de la función anterior puede verse en `Wolfram Alpha` en el enlace siguiente: <l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=derivative+of+x%5E2*sin%28x%29)</l>



El gráfico de la función anterior puede verse en `Wolfram Alpha` en el enlace siguiente: <l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=plot+of+x%5E2*sin%28x%29%2C+where+x+is+between+-2+and+2)
</l>

</div>

## Relación de la derivación con el crecimiento de una función
<l class="definition">Definición de crecimiento de una función: </l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Diremos que $f$ es **estrictamente creciente** en el punto $x_0$ si existe un entorno de $x_0$, es decir, existe un valor $\delta >0$ tal que para todo $x$ de dicho entorno diferente de $x_0$, o si $x\in (x_0-\delta,x_0+\delta)\subseteq (a,b)$, con $x\neq x_0$, se verifica que el cociente siguiente es positivo: $\frac{f(x)-f(x_0)}{x-x_0}>0$.

<l class="observ">Observación: </l> la definición anterior es equivalente a decir que existe un valor $\delta >0$ tal que si $x\in (x_0,x_0+\delta)$ o $x>x_0$, entonces $f(x)>f(x_0)$ y si $x\in (x_0-\delta)$ o $x<x_0$, entonces $f(x)<f(x_0)$. Ver gráfico siguiente.


## Relación de la derivación con el crecimiento de una función
<div class="center">
```{r, echo=FALSE, label=der2,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Derivada2.png",dpi=1200)
```
</div>


## Relación de la derivación con el crecimiento de una función
<l class="observ">Observación: </l> si la desigualdad anterior $\frac{f(x)-f(x_0)}{x-x_0}\geq 0$ no es estricta, se dice que $f$ es **creciente**.

<l class="definition">Definición de decrecimiento de una función: </l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Diremos que $f$ es **estrictamente decreciente** en el punto $x_0$ si existe un entorno de $x_0$, es decir, existe un valor $\delta >0$ tal que para todo $x$ de dicho entorno diferente de $x_0$, o si $x\in (x_0-\delta,x_0+\delta)\subseteq (a,b)$, con $x\neq x_0$, se verifica que el cociente siguiente es negativo: $\frac{f(x)-f(x_0)}{x-x_0}<0$.

## Relación de la derivación con el crecimiento de una función
<l class="observ">Observación: </l> la definición anterior es equivalente a decir que existe un valor $\delta >0$ tal que si $x\in (x_0,x_0+\delta)$ o $x>x_0$, entonces $f(x)<f(x_0)$ y si $x\in (x_0-\delta)$ o $x<x_0$, entonces $f(x)>f(x_0)$. Ver gráfico siguiente.

<l class="observ">Observación: </l> si la desigualdad anterior $\frac{f(x)-f(x_0)}{x-x_0}\leq 0$ no es estricta, se dice que $f$ es **decreciente**.



## Relación de la derivación con el crecimiento de una función
<div class="center">
```{r, echo=FALSE, label=der3,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Derivada3.png",dpi=1200)
```
</div>

## Relación de la derivación con el crecimiento de una función
<l class="prop">Proposición.</l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Supongamos que $f$ es derivable en $x_0$. Entonces si $f'(x_0)>0$ o $f$ tiene **derivada positiva** en $x_0$, entonce $f$ es **estrictamente creciente** en $x_0$.

<div class="dem">
**Demostración**

Como $\displaystyle f'(x_0)=\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}>0$, usando la definición de límite tenemos que:
$$
\forall \epsilon >0,\ \exists\delta >0\ \mbox{t.q. si }|x-x_0|<\delta,\mbox{ entonces }\left|f'(x_0)-\frac{f(x)-f(x_0)}{x-x_0}\right|< \epsilon.
$$
</div>

## Relación de la derivación con el crecimiento de una función
<div class="dem">
**Demostración**

La última condición se puede escribir de la siguiente manera:
$$
f'(x_0)-\epsilon < \frac{f(x)-f(x_0)}{x-x_0} < f'(x_0)+\epsilon.
$$
Como $f'(x_0)>0$, siempre es posible hallar un $\epsilon >0$ tal que $f'(x_0)-\epsilon>0$.

Para este $\epsilon >0$, podemos encontrar un entorno de $x_0$, es decir, un $\delta >0$ tal que si $x\in (x_0-\delta,x_0+\delta)$, entonces:
$$
0<f'(x_0)-\epsilon < \frac{f(x)-f(x_0)}{x-x_0} < f'(x_0)+\epsilon,
$$
de donde deducimos que $\frac{f(x)-f(x_0)}{x-x_0}>0$ para todo $x$ del entorno, $x\in (x_0-\delta,x_0+\delta)$, lo que equivale a decir que $f$ es estrictamente creciente en $x_0$.
</div>

## Relación de la derivación con el crecimiento de una función
<l class="prop">Proposición.</l>
Sea $f: (a,b)\longrightarrow \mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto del dominio de $f$. Supongamos que $f$ es derivable en $x_0$. Entonces si $f'(x_0)<0$ o $f$ tiene **derivada negativa** en $x_0$, entonce $f$ es **estrictamente decreciente** en $x_0$.

<div class="exercise">
**Ejercicio**

Demostrar la proposición anterior usando la misma técnica que para demostrar que si $f'(x_0)>0$, entonces $f$ es **estrictamente creciente** en $x_0$.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Consideremos la función siguiente de un ejemplo anterior: $f(x)=\sin(x)-\cos(x)$.

La derivada de la función $f$ vale: $f'(x)=\cos(x)+\sin(x)$.

Dicha función se anula en los **extremos** $x=-\frac{5}{4}\pi,-\frac{\pi}{4},\frac{3}{4}\pi$ y $\frac{7}{4}\pi$:
```{python}
def f(x):
 return(cos(x)+sin(x))
 
for x in [-5*pi/4,-pi/4,3*pi/4,7*pi/4]:
  print('f({x})={res}'.format(x=x, res=f(x)))
```

</div>

## Ejemplo
<div class="example">

En los puntos $x=-\frac{3}{2}\pi$ y $x=\frac{\pi}{2}$ la función es **estrictamente creciente** al tener derivada positiva en dichos puntos:
```{python}
for x in [-3*pi/2,pi/2]:
  print('f({x})={res}'.format(x=x, res=f(x)))
```

En cambio, en los puntos $x=-\frac{\pi}{2}$ y $\frac{3}{2}\pi$ la función es **estrictamente decreciente** al tener derivada negativa en dichos puntos:
```{python}
for x in [-pi/2,3*pi/2]:
  print('f({x})={res}'.format(x=x, res=f(x)))
```

</div>

## Teorema de Rolle. Teorema del valor medio

Las proposiciones vistas hasta ahora nos estudian el comportamiento local de una función en un punto en términos de su crecimiento dependiendo del signo de la derivada de dicha función en dicho punto.

Vamos a ver dos resultados que estudian las propiedades globales de la función en todo su dominio a partir del comportamiento de la función derivada de dicha función.

El teorema de Rolle dice en pocas palabras que si una función derivable en todo su dominio coincide en los extremos del mismo, necesariamente ha de tener como mínimo un extremo. Intuitivamente, el resultado es claro ya que si suponemos por ejemplo que la función crece en su extremo izquierdo $a$, como $f(a)=f(b)$, donde $b$ es su extremo derecho, en algún momento tiene que decrecer. Por tanto, en "dicho momento", la función tendrá un extremo o un máximo en este caso:

## Teorema de Rolle. Teorema del valor medio
<div class="center">
```{r, echo=FALSE, label=rolle1,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Rolle1.png",dpi=1200)
```
</div>

## Teorema de Rolle. Teorema del valor medio
El teorema del valor medio nos dice que dada una función derivable en todo su dominio, ha de existir un punto en el que recta tangente en dicho punto sea paralela a la recta que pasa por los extremos del dominio de la función.

En el gráfico siguiente la recta verde es la recta que pasa por los extremos de la función (en azul) y la recta roja es la recta tangente al punto $c$ que pertenece al dominio de la función.


## Teorema de Rolle. Teorema del valor medio
<div class="center">
```{r, echo=FALSE, label=valormedio1,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/ValorMedio1.png",dpi=1200)
```
</div>

## Teorema de Rolle
<l class="prop">Teorema de Rolle.</l>
Sea $f: [a,b]\longrightarrow \mathbb{R}$ una función real de variable real (!ojo!, están incluidos los extremos del intervalo). Supongamos que $f$ es continua en todo su dominio $[a,b]$ y derivable en los puntos del interior $(a,b)$. Supongamos además que las imágenes en los extremos coinciden, es decir, $f(a)=f(b)$. Entonces existe al menos un punto $c\in (a,b)$ tal que $f'(c)=0$.


## Teorema de Rolle
<div class="dem">
**Demostración**

Como la función $f$ es continua en el intervalo cerrado $[a,b]$, deducimos que $f$ tiene un máximo absoluto $M$ y un mínimo absoluto $m$. 

Pueden ocurrir dos casos:

* Que el máximo absoluto se alcance en el extremo $a$ y el mínimo, en el extremo $b$, con $f(a)=M$ y $f(b)=m$ o al revés, es decir, que el máximo absoluto se alcance en el extremo $b$ y el mínimo, en el extremo $a$, con $f(a)=m$ y $f(b)=M$. Como $f(a)=f(b)$, resulta que $M=m$ y la única función en un intervalo en donde su máximo coincide con su mínimo es la función constante. En este caso $f'(x)=0$, para todo $x\in (a,b)$ como ya vimos anteriormente y el teorema quedaría demostrado en este caso.
* Supongamos que el máximo o el mínimo de la función se alcanza en un punto $c\in (a,b)$ del interior del intervalo. Por un teorema visto anteriormente, tenemos que $f'(c)=0$ y el teorema quedaría demostrado también en este caso.
</div>

## Teorema del valor medio de Cauchy
<l class="prop">Teorema del valor medio de Cauchy.</l>
Sean $f,g:[a,b]\longrightarrow \mathbb{R}$ dos funciones continuas en $[a,b]$ y derivables en $(a,b)$. Entonces, existe un punto $c\in (a,b)$ del interior del intervalo tal que:
$$
f'(c)\cdot (g(b)-g(a)) = g'(c)\cdot (f(b)-f(a)).
$$

## Teorema del valor medio de Cauchy
<div class="dem">
**Demostración**

Consideramos la función siguiente:
$$
h(x)=f(x)\cdot (g(b)-g(a))-g(x)\cdot (f(b)-f(a)),
$$
que será continua en $[a,b]$ y derivable en $(a,b)$ al ser suma de productos de funciones continuas y derivables por constantes.

La idea es aplicar el **teorema de Rolle** a la función $h(x)$. Calculemos $h(a)$ y $h(b)$:
$$
\begin{array}{rl}
h(a) & = f(a)\cdot (g(b)-g(a))-g(a)\cdot (f(b)-f(a)) = f(a)\cdot g(b)-g(a)\cdot f(b),\\
h(b) & = f(b)\cdot (g(b)-g(a))-g(b)\cdot (f(b)-f(a)) = -f(b)\cdot g(a)+g(b)\cdot f(a).
\end{array}
$$
Se cumple, por tanto, que $h(a)=h(b)$. Aplicando el **teorema de Rolle** a la función $h$, tenemos que existe un punto $c\in (a,b)$ tal que $h'(c)=0$:
$$
h'(c)=f'(c)\cdot (g(b)-g(a))-g'(c)\cdot (f(b)-f(a))=0,
$$
de donde deducimos lo que dice la tesis del teorema:
$$
f'(c)\cdot (g(b)-g(a)) = g'(c)\cdot (f(b)-f(a)).
$$
</div>

## Teorema del valor medio de Lagrange
<l class="prop">Teorema del valor medio de Lagrange</l>
Sea $f:[a,b]\longrightarrow \mathbb{R}$ una función continua en $[a,b]$ y derivable en $(a,b)$. Entonces, existe un punto $c\in (a,b)$ del interior del intervalo tal que:
$$
f(b)-f(a)=f'(c)\cdot (b-a).
$$

<div class="exercise">
**Ejercicio**

Demostrar el teorema del valor medio de Lagrange.

Indicación: considerar $f(x)$ la función del teorema, $g(x)=x$ y aplicar el **teorema del valor medio de Cauchy**.
</div>

## Teorema del valor medio de Lagrange
<l class="observ">Observación:</l>
el **teorema del valor medio de Lagrange** es equivalente a afirmar lo que hemos dicho anteriormente: si $f$ es derivable en el intervalo abierto y continua en el cerrado, existe un valor $c$ del interior del intervalo tal que $f'(c)=\frac{f(b)-f(a)}{b-a}$, es decir, la pendiente de la recta tangente en el punto $c$ coincide con la pendiente de la recta que pasa por los extremos $(a,f(a))$ y $(b,f(b))$. Es decir, la recta tangente en el punto $c$ es paralela a la recta que pasa por los extremos del intervalo de definición de la función $f$.

## Resultados que se derivan de los teoremas de Rolle y del valor medio
<l class="prop">Corolario.</l>
Sea $f:[a,b]\longrightarrow \mathbb{R}$ una función continua en $[a,b]$ y derivable en $(a,b)$ tal que $f'(x)=0$ para todo $x\in (a,b)$. Entonces $f$ es constante.

<div class="dem">
**Demostración**

Sea $x\in (a,b]$. Veamos que $f(x)=f(a)$ y, por tanto, $f$ será constante.

Para ello, consideremos la función $f$ restringida al intervalo $[a,x]$, $f:[a,x]\longrightarrow\mathbb{R}$, que será continua en $[a,x]$ y derivable en $(a,x)$. Si aplicamos el **teorema del valor medio de Lagrange**, tenemos que existe un $c\in (a,x)$ tal que:
$$
f(x)-f(a)=f'(c)\cdot (x-a)=0,
$$
ya que nos dicen que $f'(c)=0$ al ser la derivada nula en cualquier punto del intervalo $(a,b)$.

Deducimos, por tanto, que $f(x)=f(a)$, condición que equivale a que la función $f$ es constante.
</div>


## Resultados que se derivan de los teoremas de Rolle y del valor medio
<l class="prop">Corolario.</l>
Sean $f, g:[a,b]\longrightarrow \mathbb{R}$ funciones continuas en $[a,b]$ y derivables en $(a,b)$ tal que $f'(x)=g'(x)$ para todo $x\in (a,b)$. Entonces $f(x)-g(x)$ es constante.

<div class="exercise">
**Ejercicio**

Demostrar el corolario anterior.

Indicación: aplicar el resultado que hemos visto antes a la función $h(x)=f(x)-g(x)$.
</div>


## Resultados que se derivan de los teoremas de Rolle y del valor medio
<l class="prop">Corolario.</l>
Sea $f:(a,b)\longrightarrow \mathbb{R}$ una función  derivable en todo punto del intervalo $(a,b)$.
Entonces, $f$ es creciente en $(a,b)$ si, y sólo si, $f'(x)\geq 0$, para todo $x\in (a,b)$ del intervalo.

<div class="dem">
**Demostración**

$\Rightarrow$ Supongamos que la función $f$ es creciente en $(a,b)$. Esto significa que fijado $x_0\in (a,b)$ en el intervalo, existe un entorno de $x_0$, es decir, existe un $\delta >0$, tal que para todo valor $x\in (x_0-\delta,x_0+\delta)$, se verifica que $\frac{f(x)-f(x_0)}{x-x_0}\geq 0$.

Entonces, usando que $\displaystyle f'(x_0)=\lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}$, tendremos que $f'(x_0)\geq 0$, tal como queríamos ver.
</div>

## Resultados que se derivan de los teoremas de Rolle y del valor medio

<div class="dem">
**Demostración**

$\Leftarrow$ Supongamos ahora que $f'(x_0)\geq 0$, para todo valor $x_0\in (a,b)$ dentro del intervalo. Veamos que $f$ es creciente en $x_0$. 

Sea $x>x_0$. Si aplicamos el **teorema del valor medio de Lagrange** a la función $f$ restringida al intervalo $[x_0,x]$ tenemos que existe un valor $c$ tal que: 
$$
f'(c)=\frac{f(x)-f(x_0)}{x-x_0}\geq 0.
$$
Sea ahora $x<x_0$. Si volvemos a aplicar el el **teorema del valor medio de Lagrange** a la función $f$ restringida al intervalo $[x,x_0]$ tenemos que existe un valor $c$ tal que: 
$$
f'(c)=\frac{f(x_0)-f(x)}{x_0-x}=\frac{f(x)-f(x_0)}{x-x_0}\geq 0.
$$

</div>

## Resultados que se derivan de los teoremas de Rolle y del valor medio

<div class="dem">
**Demostración**

En resumen, el cociente $\frac{f(x)-f(x_0)}{x-x_0}\geq 0$ siempre es positivo, condición que equivale a afirmar que $f$ es creciente en $x_0$.

De hecho, hubiera sido suficiente demostrar que el cociente anterior es positivo en un entorno de $x_0$ pero hemos demostrado más, hemos visto que dicho cociente siempre es positivo sea cual sea el valor $x\in (a,b)$ del intervalo.
</div>

## Resultados que se derivan de los teoremas de Rolle y del valor medio
<l class="prop">Corolario.</l>
Sea $f:(a,b)\longrightarrow \mathbb{R}$ una función  derivable en todo punto del intervalo $(a,b)$.
Entonces, $f$ es decreciente en $(a,b)$ si, y sólo si, $f'(x)\leq 0$, para todo $x\in (a,b)$ del intervalo.

<div class="exercise">
**Ejercicio**

Demostrar el corolario anterior usando la misma técnica de demostración para el caso en que la función $f$ es creciente.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Consideremos la función vista anteriormente $f(x)=\sin (x)-\cos(x)$ definida en el intervalo $(-\pi,\pi)$.

Como $f(-\pi)=1=f(\pi)$, aplicando el **teorema de Rolle**, sabemos que existe como mínimo un valor $c$ tal que $f'(c)=0$. De hecho, hay dos como hemos visto anteriormente: $c=-\frac{\pi}{4}$ y $c=\frac{3}{4}\pi$:
$$
\begin{array}{rl}
f'(x) & =\cos(x)+\sin(x),\\
f'\left(-\frac{\pi}{4}\right) & =\cos\left(-\frac{\pi}{4}\right)+\sin\left(-\frac{\pi}{4}\right)=\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2}=0,\\
f'\left(\frac{3\pi}{4}\right) & =\cos\left(\frac{3\pi}{4}\right)+\sin\left(\frac{3\pi}{4}\right)=-\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}=0.
\end{array}
$$
Si ahora consideramos la función anterior pero definida en el intervalo $\left(-\frac{\pi}{2},\frac{\pi}{2}\right)$, tenemos que existe un valor $c$ tal que:
$$
f'(c)=\cos(c)+\sin(c)=\frac{f\left(\frac{\pi}{2}\right)-f\left(-\frac{\pi}{2}\right)}{\frac{\pi}{2}-\left(-\frac{\pi}{2}\right)}=\frac{1-(-1)}{\pi}=\frac{2}{\pi}.
$$
</div>

## Ejemplo
<div class="example">
Hallemos a continuación el valor $c$:
$$
\begin{array}{rl}
\cos(c)+\sin(c) & = \frac{2}{\pi}, \\
\cos(c) & = \frac{2}{\pi}-\sin(c), \\
\pm \sqrt{1-\sin^2(c)} & = \frac{2}{\pi}-\sin(c), \\
1-\sin^2(c)  & = \left(\frac{2}{\pi}-\sin(c)\right)^2 = \frac{4}{\pi^2}+\sin^2(c)-\frac{4}{\pi}\sin(c),\\
2\sin^2(c)-\frac{4}{\pi}\sin(c)+\frac{4}{\pi^2}-1 & = 0,\\
\sin(c) & = \frac{\frac{4}{\pi}\pm \sqrt{\frac{16}{\pi^2}-8\cdot\left(\frac{4}{\pi^2}-1\right)}}{4},\\
\sin(c) & = \frac{\frac{4}{\pi}\pm \sqrt{8-\frac{16}{\pi^2}}}{4}=\frac{4\pm\sqrt{8\pi^2-16}}{4\pi}=\frac{2\pm\sqrt{2\pi^2-4}}{2\pi}.
\end{array}
$$
</div>

## Ejemplo
<div class="example">

El valor de $\cos(c)$ será:
$$
\begin{array}{rl}
\cos(c) & =\pm\sqrt{1-\left(\frac{2\pm\sqrt{2\pi^2-4}}{2\pi}\right)^2} = \pm\sqrt{1-\frac{2\pi^2\pm 4\sqrt{2\pi^2-4}}{4\pi^2}}=\pm\sqrt{\frac{2\pi^2\mp4\sqrt{2\pi^2-4}}{4\pi^2}}\\ 
& =\pm\sqrt{\frac{(2\mp\sqrt{2\pi^2-4})^2}{4\pi^2}} = \pm\frac{(2\mp\sqrt{2\pi^2-4})}{2\pi}.
\end{array}
$$
Entonces las parejas $(\sin(c),\cos(c))$ son las siguientes:

* si $\sin(c)=\frac{2+\sqrt{2\pi^2-4}}{2\pi}$, entonces $\cos(c)=\frac{2-\sqrt{2\pi^2-4}}{2\pi}$,
* si $\sin(c)=\frac{2-\sqrt{2\pi^2-4}}{2\pi}$, entonces $\cos(c)=\frac{2+\sqrt{2\pi^2-4}}{2\pi}$.

El primer caso no puede ser ya que $\cos(c)<0$ y como estamos en el intervalo $\left(-\frac{\pi}{2},\frac{\pi}{2}\right)$, la función coseno es positiva.

Sólo será solución el segundo caso, donde el valor de $c$ será aproximadamente: `r round(asin((2-sqrt(2*pi^2-4))/(2*pi)),3)`.

</div>

</div>

## Ejemplo
<div class="example">
Comprobemos usando `python` que el valor de $c$ hallado es el correcto:

```{python}
from numpy import * 
c=arcsin((2-sqrt(2*pi**2-4))/(2*pi))
derivada_c = sin(c)+cos(c)
k=2/pi
print('El valor de c es: {c}'.format(c=c))

```

</div>

## Ejemplo
<div class="example">
```{python}
print('El valor de la derivada de f en c es:{x}'.format(x=derivada_c))
print('El valor de 2/pi es:{k}'.format(k=k))
```

</div>

## Regla de L'Hôpital

Una de las aplicaciones más importantes de las derivadas es su aplicación al cálculo de límites de funciones.

La regla de L'Hôpital nos permite calcular límites indeterminados usando derivadas:

## Regla de L'Hôpital
<l class="prop">Teorema: regla de L'Hôpital.</l>
Sean $f,g:(a,b)\longrightarrow\mathbb{R}$ y sea $c\in (a,b)$ un punto interior del intervalo. Supongamos:

* $f$ y $g$ son derivables en un entorno del punto $c$,
* $f(c)=g(c)=0$,
* $g(x)\neq 0$ para todo valor $x$ del entorno de $c$ diferente de $c$,
* $g'(x)\neq 0$, para todo valor $x$ del entorno de $c$ diferente de $c$.

Si se verifican las condiciones anteriores y el límite siguiente existe $\displaystyle\lim_{x\to c}\frac{f'(x)}{g'(x)}=L$ y vale $L$ ($L$ puede ser $\pm\infty$), entonces también existe el límite $\displaystyle\lim_{x\to c}\frac{f(x)}{g(x)}=L$ y vale $L$.


## Regla de L'Hôpital
<div class="dem">
**Demostración**

Sea $\delta >0$ tal que $(c-\delta,c+\delta)\subseteq (a,b)$ en entorno de $c$ donde se cumplen las condiciones del teorema. 

Sea $x\in (c-\delta,c+\delta)$ un valor del entorno. Podemos afirmar que en intervalo $[c,x]$ se cumplen las hipótesis del **teorema del valor medio de Cauchy** ya que $f$ y $g$ son derivables en $(c,x)$ al serlo en todo el entorno $(c-\delta,c+\delta)$ y continuas en $[c,x]$ ya que como son derivables en todo en entorno, serán continuas y como $[c,x]\subset (c-\delta,c+\delta)$, también serán continuas en el intervalo $[c,x]$.

Usando por tanto el **teorema del valor medio de Cauchy**, podemos afirmar que existe un punto $d\in (c,x)$ tal que:
$$
f'(d)\cdot (g(d)-g(c))=g'(d)\cdot (f(d)-f(c)).
$$
Recordemos que $f(c)=g(c)=0$, $f'(d)\neq 0$ y $g'(d)\neq 0$ ya que suponíamos que las derivadas $f'$ y $g'$ no se anulaban en el entorno de $c$. Usando las condiciones anteriores, podemos simplificar la expresión anterior de la siguiente manera:
$$
\frac{f'(d)}{g'(d)}=\frac{f(d)}{g(d)}.
$$
</div>

## Regla de L'Hôpital
<div class="dem">

Si hacemos tender $x\to c$, como $d\in (c,x)$, tendremos que $d\to c$. Por tanto,
$$
\lim_{x\to c}\frac{f(x)}{g(x)}=\lim_{x\to c}\frac{f'(x)}{g'(x)}=L,
$$
por hipótesis. 

En resumen, si existe $\displaystyle \lim_{x\to c}\frac{f'(x)}{g'(x)}$, también existe el límite $\displaystyle \lim_{x\to c}\frac{f(x)}{g(x)}$ y los dos coinciden.
</div>

<l class="observ">Observación:</l> el teorema sigue siendo cierto en el caso en que $a$, $b$, $c$ o $L$ son $\pm \infty$. Es decir, si existe el límite $\displaystyle \lim_{x\to \pm\infty}\frac{f'(x)}{g'(x)}$, también existe el límite $\displaystyle \lim_{x\to \pm\infty}\frac{f(x)}{g(x)}$ y los dos coinciden y pueden tener como resultado $\pm\infty$.

## Ejemplo
<div class="example">
**Ejemplo**

Calculemos el valor del límite siguiente $\displaystyle\lim_{x\to 0}\frac{\sin x-x}{x-x\cos x}$.

Observemos que si sustituimos por el valor $0$, obtenemos la indeterminación $\frac{0}{0}$.

Usando la regla de L'Hôpital, calculemos el límite anterior:
$$
\lim_{x\to 0}\frac{\sin x-x}{x-x\cos x} = \lim_{x\to 0}\frac{\cos x-1}{1-\cos x+x\sin x}=\frac{0}{0}.
$$
Nos vuelve a dar la indeterminación $\frac{0}{0}$. Aplicando la regla de L'Hôpital por segunda vez, obtenemos:
$$
\lim_{x\to 0}\frac{\cos x-1}{1-\cos x+x\sin x} =\lim_{x\to 0}\frac{-\sin x}{\sin x+\sin x+x\cos x}=\lim_{x\to 0}\frac{-\sin x}{2\sin x+x\cos x}=\frac{0}{0}.
$$
</div>

## Ejemplo
<div class="example">
Nos vuelve a dar la indeterminación $\frac{0}{0}$. Aplicando la regla de L'Hôpital por tercera vez, obtenemos:
$$
\lim_{x\to 0}\frac{-\sin x}{2\sin x+x\cos x} =\lim_{x\to 0}\frac{-\cos x}{2\cos x+\cos x-x\sin x}=\frac{-1}{3}.
$$
El límite tiene el valor $-\frac{1}{3}$.

El límite anterior en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=limit+of+%28sin%28x%29-x%29%2F%28x-x*cos%28x%29%29+when+x+tends+to+0)
</l>
</div>

## Regla de L'Hôpital
<div class="box">
<div class="important">
<i class="fa fa-exclamation-triangle"> ¡Cuidado! </i>
</div>
La regla de L'Hôpital sólo se puede aplicar en un sentido. Es decir, si existe el límite $\displaystyle \lim_{x\to c}\frac{f'(x)}{g'(x)}$, bajo las condiciones del Teorema anterior, existe el $\displaystyle \lim_{x\to c}\frac{f(x)}{g(x)}$ y son iguales; ahora bien, si no existe el límite $\displaystyle \lim_{x\to c}\frac{f'(x)}{g'(x)}$, no podemos decir nada acerca del límite $\displaystyle \lim_{x\to c}\frac{f(x)}{g(x)}$. Véase el ejemplo siguiente.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Consideremos el límite siguiente:
$\displaystyle\lim_{x\to 0}\frac{x^2\sin\left(\frac{1}{x}\right)}{\sin x}.$

Si sustituimos $x$ por $0$ en el límite anterior obtenemos el valor $\frac{0}{0}$, pensad que $\displaystyle\lim_{x\to 0}x^2\sin\left(\frac{1}{x}\right)=0$ vale $0$ ya que es el límite de una funció que tiende a 0 ($x^2$) por una función acotada ($\sin\left(\frac{1}{x}\right)$).

Apliquemos pues la regla de l'Hôpital:
$$
\begin{array}{rl}
\displaystyle\lim_{x\to 0}\frac{x^2\sin\left(\frac{1}{x}\right)}{\sin x} & \displaystyle =\lim_{x\to 0}\frac{2x\sin\left(\frac{1}{x}\right)+x^2\cdot \left(-\frac{1}{x^2}\cos\left(\frac{1}{x}\right)\right)}{\cos x}=
\lim_{x\to 0}\frac{2x\sin\left(\frac{1}{x}\right)-\cos\left(\frac{1}{x}\right)}{\cos x} \\ & \displaystyle =\lim_{x\to 0} \frac{2x\sin\left(\frac{1}{x}\right)}{\cos x}-\lim_{x\to 0}\frac{\cos\left(\frac{1}{x}\right)}{\cos x} = 0-\lim_{x\to 0}\frac{\cos\left(\frac{1}{x}\right)}{\cos x} = -\lim_{x\to 0}\frac{\cos\left(\frac{1}{x}\right)}{\cos x}.
\end{array}
$$
El límite $\displaystyle \lim_{x\to 0} \frac{2x\sin\left(\frac{1}{x}\right)}{\cos x}$ vale $0$ ya que el denominador tiende a $1$ cuando $x\to 0$ y el numerador es el límite de una función que tiende a $0$ ($2x$) por una función acotada ($\sin\left(\frac{1}{x}\right)$).

</div>

## Ejemplo
<div class="example">
El límite anterior no existe ya que si consideramos la sucesión $x_n=\frac{1}{2\pi n}\longrightarrow 0$, si $n\to\infty$, el límite de la sucesión $\frac{\cos\left(\frac{1}{x_n}\right)}{\cos x_n}$ vale:
$$
-\lim_{n\to\infty}\frac{\cos (2\pi n)}{\cos\left(\frac{1}{2\pi n}\right)}=-1.
$$
En cambio, si consideramos la sucesión $y_n =\frac{1}{\frac{\pi}{2}+2\pi n}\longrightarrow 0$, si $n\to\infty$, el límite de la sucesión $\frac{\cos\left(\frac{1}{y_n}\right)}{\cos y_n}$ vale:
$$
-\lim_{n\to\infty}\frac{\cos \left(\frac{\pi}{2}+2\pi n\right)}{\cos\left(\frac{1}{\frac{\pi}{2}+2\pi n}\right)}=0.
$$

</div>

## Ejemplo
<div class="example">
A continuación estaríamos tentados a decir que nuestro límite inicial $\displaystyle\lim_{x\to 0}\frac{x^2\sin\left(\frac{1}{x}\right)}{\sin x}$ no existe pero esto es falso ya que:
$$
\lim_{x\to 0}\frac{x^2\sin\left(\frac{1}{x}\right)}{\sin x}= \lim_{x\to 0}\frac{x}{\sin x}\cdot \lim_{x\to 0}
 x\sin\left(\frac{1}{x}\right)=1\cdot 0=0!
$$
El primer límite $\displaystyle \lim_{x\to 0}\frac{x}{\sin x}$ vale $1$ ya que vimos en su momento que $\displaystyle \lim_{x\to 0}\frac{\sin x}{x}=1$, por tanto, si hacemos el límite de su recíproco también será $1$: $\displaystyle \lim_{x\to 0}\frac{x}{\sin x}=1$.

El segundo límite $\displaystyle \lim_{x\to 0} x\sin\left(\frac{1}{x}\right)$ vale $0$ ya que es el límite de una función que tiende a $0$ ($x$) por una función acotada ($\sin\left(\frac{1}{x}\right)$).

</div>

## Ejemplo
<div class="example">
En resumen, que no exista el límite una vez aplicada la regla de l'Hôpital no significa que no exista el límite inicial que nos hemos planteado.

El límite anterior en `Wolfram Alpha` se muestra en el enlace siguiente:
<l class="center">
[![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=limit+of+%28x%5E2*sin%281%2Fx%29%29%2Fsin%28x%29+when+x+tends+to+0)
</l>
</div>

# Fórmula de Taylor

## Introducción

La idea fundamental de la **fórmula de Taylor** es aproximar localmente una función en un entorno de un valor determinado por las funciones más sencillas que se conocen, los polinomios.

Dicho de manera más explícita, consideremos una función $f:(a,b)\longrightarrow\mathbb{R}$ que se puede derivar hasta un cierto orden, pongamos $n+1$, para un cierto valor $n$ natural, y sea $x_0\in (a,b)$ un valor del interior del dominio de $f$. Queremos hallar un polinomio $P_n(x)$ tal que se verifique que $f$ y $P_n$ sean "iguales" en $x_0$ hasta orden $n$:
$$
\lim_{x\to x_0}\frac{f(x)-P_n(x)}{(x-x_0)^n} =0,\mbox{ para }m=0,1,\ldots,n.
$$

## Introducción
La condición anterior para $m=0$ es la siguiente:
$$
\lim_{x\to x_0}f(x)-P_n(x) =0,\ \Rightarrow P_n(x_0)=f(x_0),
$$
es decir, la función y el polinomio a hallar deben coincidir en el valor $x_0$.

## Introducción
La condición anterior para $m=1$ es la siguiente:
$$
\lim_{x\to x_0}\frac{f(x)-P_n(x)}{(x-x_0)} =0,\ \Rightarrow P_n'(x_0)=f'(x_0),
$$
es decir, la derivada de la función y el polinomio a hallar deben coincidir en el valor $x_0$ ya que si aplicamos la regla de L'Hôpital (el límite es indeterminado de la forma $\frac{0}{0}$ ya que recordemos que $P_n(x_0)=f(x_0)$):
$$
\lim_{x\to x_0}\frac{f(x)-P_n(x)}{(x-x_0)} = \lim_{x\to x_0}\frac{f'(x)-P_n'(x)}{(x-x_0)}=0,
$$
y el numerador debe ser $0$ para $x=x_0$ ya que en caso contrario el límite anterior sería de la forma $\frac{f'(x_0)-P_n'(x_0)}{0}=\infty$, al ser el numerador diferente de $0$.

## Introducción
En general, la condición para $m$ entre $0$ y $n$ es la siguiente:
$$
\lim_{x\to x_0}\frac{f(x)-P_n(x)}{(x-x_0)^m} =0,\ \Rightarrow P_n^{(m)}(x_0)=f^{(m)}(x_0),
$$
es decir, la derivada $m$-ésima de la función y el polinomio a hallar deben coincidir en el valor $x_0$ ya que si aplicamos la regla de L'Hôpital $m$ veces (el límite es indeterminado de la forma $\frac{0}{0}$ ya que recordemos que $P_n^{(i)}(x_0)=f^{(i)}(x_0)$ para los $i$ anteriores desde $0$ hasta $m-1$):
$$
\lim_{x\to x_0}\frac{f(x)-P_n(x)}{(x-x_0)^m} = \lim_{x\to x_0}\frac{f'(x)-P_n(x)}{m (x-x_0)^{m-1}}=\cdots = \lim_{x\to x_0}\frac{f^{(m)}(x)-P_n^{(m)}(x)}{m! (x-x_0)}=0,
$$

## Introducción
y el numerador debe ser $0$ para $x=x_0$ ya que en caso contrario el límite anterior sería de la forma $\frac{f^{(m)}(x_0)-P_n^{(m)}(x_0)}{0}=\infty$, al ser el numerador diferente de $0$.


<div class="box">
<div class="important">
<i class="fa fa-star"> Importante: </i>
</div>
Las condiciones que debe verificar el polinomio $P_n(x)$ para aproximar la función $f(x)$ hasta orden $n$ en un entorno del punto $x_0$ son las siguientes:
$$
P_n^{(m)}(x_0)=f^{(m)}(x_0),\mbox{ para }m=0,\ldots,n.
$$
En este caso decimos que el polinomio $P_n(x)$ tiene en el punto $x_0$ **orden de contacto** con $f$ superior a $n$.
</div>

## Introducción
<div class="example">
**Ejemplo ilustrativo**

En el enlace siguiente  [![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=taylors+series+of+sin%28x%29+at+x%3D0) se muestra la función $f(x)=\sin x$ (en rojo) y los polinomios de grado $1$, $P_1(x)$ (la recta en azul discontinua), de grado $3$, $P_3(x)$ (la curva en azul discontinua) para $x_0=0$. El polinomio $P_2(x)$ coincide con el polinomio de grado $1$ en este caso ya que el coeficiente de $x^2$ vale $0$ como veremos más adelante.

En la casilla *expansion point* podéis cambiar el valor $x_0$. Intentad escribir `pi/2` y `pi` y observad qué ocurre.

Si clicáis en la casilla *More terms* en la parte de arriba del gráfico veréis los polinomios de grado $5$, $P_5(x)$ y de grado $7$, $P_7(x)$. Observad cómo cada vez los polinomios se aproximan más a la función $f(x)$.

</div>

<l class="observ">Observación: </l> la elección del punto $x_0$ no es arbitraria. Hemos de elegir un valor $x_0$ del que conozcamos el valor $f(x_0)$ y las derivadas de cualquier orden en $x_0$, $f^{(m)}(x_0)$, $m=1,2,\ldots$


## Introducción
<div class="example">
**Ejemplo anterior**

En el ejemplo anterior donde recordemos que $f(x)=\sin x$, debemos elegir un punto $x_0$ en el cual conozcamos los valores de $\sin x_0$ y $\cos x_0$ ya que si conocemos dichos valores, conoceremos $f(x_0)$ y las derivadas de cualquier orden:
$$
f(x_0)=\sin x_0,\ f'(x_0)=\cos x_0,\ f''(x_0)=-\sin x_0,\ f'''(x_0)=-\cos x_0,\ f^{iv}(x_0)=\sin x_0,\ldots
$$
Algunos valores $x_0$ elegibles en este caso son los siguientes: $x_0=0,\frac{\pi}{6}, \frac{\pi}{4},\frac{\pi}{3},\frac{\pi}{2},\pi$ ya que conocemos el valor de $\sin (x_0)$ y $\cos(x_0)$ tal como se observa en la tabla siguiente:

<div class="center">
|$x_0$| $0$| $\frac{\pi}{6}$| $\frac{\pi}{4}$|$\frac{\pi}{3}$|$\frac{\pi}{2}$|$\pi$|
|---|:---:|:---:|:---:|:---:|:---:|:---:|
$\sin(x_0)$|$0$|$\frac{1}{2}$|$\frac{\sqrt{2}}{2}$|$\frac{\sqrt{3}}{2}$|$1$|$0$|
$\cos(x_0)$|$1$|$\frac{\sqrt{3}}{2}$|$\frac{\sqrt{2}}{2}$|$\frac{1}{2}$|$0$|$-1$|
</div>
</div>


## Cálculo del polinomio de Taylor
El resultado siguiente nos da una expresión del polinomio de Taylor:

<l class="prop">Teorema. Expresión del polinomio de Taylor o la expansión de Taylor.</l>
Sea $n$ un valor natural. Sea $f:(a,b)\longrightarrow\mathbb{R}$ una función real de variable real. Sea $x_0\in (a,b)$ un punto interior del dominio de $f$. Supongamos que $f$ es derivable $n+1$ veces en $x_0$. Entonces el polinomio de Taylor de grado $n$ con **orden de contacto** con $f$ superior a $n$ en $x_0$ es el siguiente:
$$
\begin{array}{rl}
P_n(x) = & f(x_0)+f'(x_0)\cdot (x-x_0)+\frac{f''(x_0)}{2!}\cdot (x-x_0)^2+\cdots +\\ & +\frac{f^{(n)}(x_0)}{n!}\cdot (x-x_0)^n.
\end{array}
$$


## Cálculo del polinomio de Taylor
<div class="box">
<div class="important">
<i class="fa fa-dizzy"> Contenido bastante técnico. </i>
</div>
</div>

<div class="dem">
**Demostración**

Vamos a demostrar la fórmula anterior por inducción sobre $n$.

Para $n=0$, $P_0(x)=f(x_0)$, que por definición es el **polinomio de Taylor** de grado $0$ o constante.

Suponemos cierto para $n$, es decir suponemos que:
$$
P_n(x) =  f(x_0)+f'(x_0)\cdot (x-x_0)+\frac{f''(x_0)}{2!}\cdot (x-x_0)^2+\cdots  +\frac{f^{(n)}(x_0)}{n!}\cdot (x-x_0)^n.
$$
Hemos de demostrar que:
$$
\begin{array}{rl}
P_{n+1}(x) = & f(x_0)+f'(x_0)\cdot (x-x_0)+\frac{f''(x_0)}{2!}\cdot (x-x_0)^2+\cdots + \frac{f^{(n)}(x_0)}{n!}\cdot (x-x_0)^n+\\ & +\frac{f^{(n+1)}(x_0)}{(n+1)!}\cdot (x-x_0)^{n+1} = P_n(x)+\frac{f^{(n+1)}(x_0)}{(n+1)!}\cdot (x-x_0)^{n+1}.
\end{array}
$$

</div>

## Cálculo del polinomio de Taylor
<div class="dem">
Por hipótesis de inducción, sabemos que: $P_n^{(i)}(x_0)=f^{(i)}(x_0)$, para $i=0,\ldots,n$ ya que recordemos que $P_n(x)$ es el polinomio de Taylor de grado $n$.

Para verificar que $P_{n+1}(x)$ correspondiente a la expresión anterior es el polinomio de Taylor de grado $n+1$, hay que verificar las condiciones siguientes: $P_{n+1}^{(i)}(x_0)=f^{(i)}(x_0)$, para $i=0,\ldots,n+1$.

Si $i$ está entre $0$ y $n$, tenemos que:
$$
P_{n+1}^{(i)}(x)=P_{n}^{(i)}(x)+(n+1)\cdots (n+2-i)\cdot\frac{f^{(n+1)}(x_0)}{(n+1)!}\cdot (x-x_0)^{n+1-i}.
$$
Si evaluamos la expresión anterior en $x=x_0$, obtenemos:
$$
P_{n+1}^{(i)}(x_0)=P_{n}^{(i)}(x_0)+(n+1)\cdots (n+2-i)\cdot\frac{f^{(n+1)}(x_0)}{(n+1)!}\cdot (x_0-x_0)^{n+1-i} = P_n^{(i)}(x_0)=f^{(i)}(x_0),
$$
ya que $n+1-i>0$ por lo que el segundo sumando será nulo y la última igualdad es cierta por hipótesis de inducción.
</div>

## Cálculo del polinomio de Taylor
<div class="dem">
Sólo falta demostrar el caso $i=n+1$. Si hacemos la derivada $n+1$-ésima del polinomio $P_{n+1}(x)$ obtenemos:
$$
P_{n+1}^{(n+1)}(x)=P_n^{(n+1)}(x)+f^{(n+1)}(x_0) = f^{(n+1)}(x_0),
$$
ya que $P_n^{(n+1)}(x)=0$ al ser $P_n(x)$ un polinomio de grado $n$ y por tanto la derivada $n+1$-ésima del mismo será 0.

Concluimos por tanto que la derivada $n+1$-ésima del polinomio $P_{n+1}(x)$ será la constante $f^{(n+1)}(x_0)$ y, en particular, se cumplirá que $P_{n+1}^{(n+1)}(x_0)=f^{(n+1)}(x_0)$, tal como queríamos demostrar.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Consideremos la función $f(x)=\sin (x)$ y el punto $x_0=0$. Vamos a hallar el polinomio de Taylor de grado $n$ de $f(x)$ en $x_0=0$.

Lo primero que hemos de calcular a la vista de la expresión vista en el teorema anterior que nos da la expresión del polinomio de Taylor es el valor de la función en $x_0$, $f(x_0)$ y el valor de las derivadas de $f$ en $x_0$, $f^{(m)}(x_0)$, para $m=1,2,\ldots$

Los valores de $f^{(m)}(0)$ valen lo siguiente:
$$
f(0)=\sin 0=0,\ f'(0)=\cos 0=1,\ f''(0)=-\sin 0=0,\ f'''(0)=-\cos 0 =-1,\ f^{(iv)}(0)=\sin 0 =0, \ldots
$$
A partir de los cálculos anteriores podemos deducir que $f^{(n)}(0)=0$, si $n$ es par y $f^{(n)}(0)=\pm 1$, si $n$ es impar y valdrá $1$ si $n=1,5,9,\ldots$ y $-1$ si $n=3,7,11,\ldots$

Intentemos escribir el resultado anterior de forma más "compacta". Decir que $n$ es par es equivalente a decir que existe un valor $k$ natural tal que $n=2k$ y decir que $n$ es impar es equivalente a decir que existe un valor $k$ natural tal que $n=2k+1$. Por tanto, las condiciones anteriores se pueden escribir como: $f^{(2k)}(0)=0$, $f^{(2k+1)}(0)=\pm 1$.
</div>

## Ejemplo
<div class="example">

Observemos además que los valores de $n$ para los que la derivada $n$-ésima valía $1$, ($n=1,5,9,\ldots$) corresponde a valores de $k$ par ya que $1=2\cdot 0+1,\ 5=2\cdot 2+1,\ 9=2\cdot 4+1,\ldots$ y los valores de $n$ para los que la derivada $n$-ésima valía $-1$ ($n=3,7,11,\ldots$) corresponde a valores de $k$ impar ya que $3=2\cdot 1+1,\ 7=2\cdot 3+1,\ 11=2\cdot 5+1,\ldots$

Por tanto, la condición $f^{(2k+1)}(0)=\pm 1$ puede escribirse como $f^{(2k+1)}(0)=(-1)^k$ ya que la expresión $(-1)^k$ da $1$ para los $k$ pares y $-1$, para los $k$ impares.

En resumen, tenemos lo siguiente: $f^{(2k)}(0)=0$, $f^{(2k+1)}(0)=(-1)^k$, para $k=0,1,2,3,\ldots$

Sea $n$ un natural. Consideremos dos casos:

* $n$ par. En este caso, el polinomio de Taylor de grado $n$ es el siguiente:
$$
P_n(x)=f(0)+f'(0)\cdot x+\frac{f''(0)}{2!}\cdot x^2+\cdots + \frac{f^{n}(0)}{n!}\cdot x^n.
$$
Observemos que el último término del polinomio anterior será $0$ ya que hemos dicho que $f^{(n)}(0)=0$ para $n$ par.
Entonces el polinomio $P_n(x)$ se puede escribir como:
$$
P_n(x)=f(0)+f'(0)\cdot x+\frac{f''(0)}{2!}\cdot x^2+\cdots + \frac{f^{n-1}(0)}{(n-1)!}\cdot x^{n-1}.
$$

</div>

## Ejemplo
<div class="example">
Si eliminamos los términos correspondientes a derivadas pares al ser nulos, nos queda la expresión siguiente:
$$
P_n(x)=x-\frac{x^3}{3!}+\frac{x^5}{5!}+\cdots + \frac{(-1)^k x^{2k+1}}{(2k+1)!}=\sum_{i=0}^k \frac{(-1)^i x^{2i+1}}{(2i+1)!},
$$
donde $k$ es tal que $n-1=2k+1$, o, lo que es lo mismo, $k=\frac{n-2}{2}$.
```{r,echo=FALSE}
options(scipen=999)
```
Consideremos por ejemplo $n=14$, en este caso $k=\frac{14-2}{2}=6$. El polinomio de Taylor de $f(x)=\sin x$ de grado $14$ en $x_0=0$ es el siguiente:
$$
\begin{array}{rl}
P_{14}(x) & =x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\frac{x^9}{9!}-\frac{x^{11}}{11!}+\frac{x^{13}}{13!},\\
& = x-\frac{x^3}{`r factorial(3)`}+\frac{x^5}{`r factorial(5)`}-\frac{x^7}{`r factorial(7)`}+\frac{x^9}{`r factorial(9)`}-\frac{x^{11}}{`r factorial(11)`}+\frac{x^{13}}{`r factorial(13)`}.
\end{array}
$$
</div>

## Ejemplo
<div class="example">
* $n$ impar. En este caso, el polinomio de Taylor de grado $n$ es el siguiente:
$$
P_n(x)=f(0)+f'(0)\cdot x+\frac{f''(0)}{2!}\cdot x^2+\cdots + \frac{f^{n}(0)}{n!}\cdot x^n.
$$
Si eliminamos los términos correspondientes a derivadas pares al ser nulos, nos queda la expresión siguiente:
$$
P_n(x)=x-\frac{x^3}{3!}+\frac{x^5}{5!}+\cdots + \frac{(-1)^k x^{2k+1}}{(2k+1)!}=\sum_{i=0}^k \frac{(-1)^i x^{2i+1}}{(2i+1)!},
$$
donde $k$ es tal que $n=2k+1$, o, lo que es lo mismo, $k=\frac{n-1}{2}$.
Consideremos por ejemplo $n=11$, en este caso $k=\frac{11-1}{2}=5$. El polinomio de Taylor de $f(x)=\sin x$ de grado $11$ en $x_0=0$ es el siguiente:
$$
P_{11}(x)  =x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\frac{x^9}{9!}-\frac{x^{11}}{11!}
 = x-\frac{x^3}{`r factorial(3)`}+\frac{x^5}{`r factorial(5)`}-\frac{x^7}{`r factorial(7)`}+\frac{x^9}{`r factorial(9)`}-\frac{x^{11}}{`r factorial(11)`}.
$$
Si váis al enlace siguiente  [![](Images/wolfram.png)](https://www.wolframalpha.com/input/?i=taylors+series+of+sin%28x%29+at+x%3D0) y apretáis una vez la casilla `More terms` en la sección `Series expansion at x=0` os aparecerá el polinomio de Taylor de grado 11 y si volvéis a apretar, os aparecerá el polinomio de Taylor de grado 19 que "incluye" el polinomio de Taylor de grado 14.

</div>


## Desarrollos de MacLaurin

<div class="exercise">
**Ejercicio**

Hallar el polinomio de Taylor de grado $n$ para la misma función que el ejemplo anterior en el punto $x_0=\frac{\pi}{2}$.
</div>

<l class="definition">Definición.</l> Dada una función $f:(a,b)\longrightarrow \mathbb{R}$, $n+1$ veces derivable y dado $x_0\in (a,b)$ un punto interior del dominio de $f$, sea $P_n(x)$ el polinomio de Taylor de grado $n$ en $x_0=0$. Dicho polinomio se denomina **polinomio o expansión de MacLaurin de grado $n$ de $f$ **.

En el ejemplo anterior, hemos hallado el polinomio de MacLaurin de grado $n$ de la función $f(x)=\sin x$.



## Error en el polinomio de Taylor

Una vez conocido cómo hallar el **polinomio de Taylor** de una función $f(x)$ en un punto $x_0$ de su dominio, podemos usar dicho polinomio o dicha expansión para **aproximar** el valor de dicha función $f(x)$ para valores $x$ **cercanos** a $x_0$.

Ahora bien, si no tenemos manera de estimar o calcular alguna **cota del error** que estamos cometiendo, dicha aproximación no tiene ningún sentido ya que sería como "ir a ciegas", es decir, no sabemos hasta qué punto el valor $P_n(x)$ aproxima bien o no el valor de $f(x)$.

El siguiente resultado nos da una expresión que permite acotar el error cometido usando el polinomio de Taylor.

## Error en el polinomio de Taylor

<l class="prop">Teorema. Error en la fórmula de Taylor. </l>
Sea $f$ una función $f:(a,b)\longrightarrow \mathbb{R}$, sea $x_0\in (a,b)$ un punto interior del dominio de $f$ y supongamos que $f$ es $n+1$ veces derivable en un entorno de $x_0$. Sea $P_n(x)$ el polinomio de Taylor de grado $n$ en $x_0$. Entonces si $x$ es un punto del entorno anterior de $x_0$, se verifica:
$$
f(x)-P_n(x)=\frac{f^{n+1}(c)}{m\cdot n!}\cdot (x-c)^{n-m+1}\cdot (x-x_0)^m,
$$
donde $c$ es un punto que está situado entre $x_0$ y $x$ (o entre $x$ y $x_0$, dependiendo de cuál de los dos valores es el menor y el mayor) y se denota por $x\in <x_0,x>$ y $m$ es un natural entre $1$ y $n+1$.
Dicha expresión es conocida por **resto de Cauchy**.

## Error en el polinomio de Taylor
<l class="observ">Observación:</l> a la expresión $f(x)-P_n(x)$ se le denota por $R_n(x-x_0)$, $R$ de resto.

<l class="prop">Corolario.</l>
En las condiciones del teorema anterior, considerando $m=n+1$, tenemos la expresión siguiente conocida como **resto de Lagrange**:
$$
f(x)-P_n(x)=\frac{f^{n+1}(c)}{(n+1)!}\cdot (x-x_0)^{n+1}.
$$

Esta es la expresión más conocida de la expresión del error del **polinomio de Taylor** de grado $n$.

## Error en el polinomio de Taylor
<div class="box">
<div class="important">
<i class="fa fa-dizzy"> <i class="fa fa-dizzy"> Contenido muy técnico. </i></i>
</div>
</div>

<div class="dem">
**Demostración**

Sea $x\in (a,b)$ un valor del interior del entorno de $x_0$ donde $f$ es $n+1$ veces derivable. Fijado dicho valor de $x$, se considera la función siguiente que depende de la variable $t$:
$$
F(t)=f(t)+\sum_{k=1}^n \frac{f^{(k)}(t)}{k!}\cdot (x-t)^k.
$$
Dicha función $F(t)$ es continua y derivable en el intervalo $<x_0,x>$ (recordemos que dicha expresión vale $(x_0,x)$, si $x>x_0$ y $(x,x_0)$ si $x<x_0$) ya que es suma de productos de continuas y derivables:
pensad que $f$ es derivable por hipótesis, $f^{(k)}$ será derivable ya que $k\leq n$ y por ser $f$ derivable $n+1$ veces por hipótesis y la función $(x-t)^k$ será derivable al ser un polinomio en $t$.
</div>

## Error en el polinomio de Taylor
<div class="dem">
Hallemos el valor de la derivada de $F$, $F'(t)$:
$$
\begin{array}{rl}
F'(t)   = & \displaystyle f'(t)+\sum_{k=1}^n \frac{f^{(k+1)}(t)}{k!}\cdot (x-t)^k -\sum_{k=1}^n k\cdot \frac{f^{(k)}(t)}{k!}(x-t)^{k-1} \\
 = &\displaystyle f'(t)+\sum_{k=1}^n \frac{f^{(k+1)}(t)}{k!}\cdot (x-t)^k -\sum_{k=1}^n \frac{f^{(k)}(t)}{(k-1)!}(x-t)^{k-1}\\
 = &  f'(t)+\frac{f''(t)}{1!}\cdot (x-t)+\frac{f'''(t)}{2!}\cdot (x-t)^2+\cdots+ \frac{f^{(n)}(t)}{(n-1)!}\cdot (x-t)^{n-1} + \frac{f^{(n+1)}(t)}{n!}\cdot (x-t)^n\\ & -\left(f'(t)+\frac{f''(t)}{1!}\cdot (x-t)+\frac{f'''(t)}{2!}\cdot (x-t)^2 +\cdots + \frac{f^{(n)}(t)}{(n-1)!}\cdot (x-t)^{n-1} \right) = \frac{f^{(n+1)}(t)}{n!}\cdot (x-t)^n.
\end{array}
$$
Consideremos ahora una función $G$ cualquiera continua en el intervalo $<x_0,x>$ cerrado y diferenciable en el mismo intervalo anterior pero abierto tal que $G'(t)\neq 0$ para todo $t\in <x_0,x>$ y $G(x_0)\neq G(x)$.

Si aplicamos el Teorema del valor medio de Cauchy al intervalo $<x_0,x>$ a las funciones $F$ y $G$, tenemos que existe un valor $c\in <x_0,x>$ tal que:
$$
G'(c)\cdot (F(x)-F(x_0))=F'(c)\cdot (G(x)-G(x_0)).
$$

</div>

## Error en el polinomio de Taylor
<div class="dem">
El valor de $F(x)-F(x_0)$ es precisamente el error que cometemos al aproximar $f(x)$ por el polinomio de Taylor de grado $n$, $P_n(x)$ ya que:
$$
F(x)-F(x_0)=f(t)-\left(f(x_0)+\sum_{k=1}^n \frac{f^{(k)}(x_0)}{k!}\cdot (x-x_0)^k\right)=f(x)-P_n(x).
$$
Usando la expresión deducida del Teorema del valor medio de Cauchy, podemos escribir que:
$$
F(x)-F(x_0)=f(x)-P_n(x)=R_n(x-x_0)=\frac{F'(c)}{G'(c)}\cdot (G(x)-G(x_0)).
$$
Diferentes expresiones del error se obtienen eligiendo $G$ de una determinada forma:

* Si $G(t)=(x-t)^{n+1}$, tenemos que $G'(t)=-(n+1)\cdot (x-t)^n$ y, por tanto:
$$
R_n(x-x_0)=\frac{F'(c)}{G'(c)}\cdot (G(x)-G(x_0))=\frac{\frac{f^{(n+1)}(c)}{n!}\cdot (x-c)^n}{-(n+1)\cdot (x-c)^n}\cdot \left(-(x-x_0)^{n+1}\right)=\frac{f^{(n+1)}(c)}{(n+1)!}\cdot (x-x_0)^{n+1}.
$$


</div>

## Error en el polinomio de Taylor
<div class="dem">
* Si $G(t)=(x-t)^{m}$, con $m$ natural entre $1$ y $n+1$, tenemos que $G'(t)=-m\cdot (x-t)^{m-1}$ y, por tanto:
$$
\begin{array}{rl}
R_n(x-x_0) & =\frac{F'(c)}{G'(c)}\cdot (G(x)-G(x_0))=\frac{\frac{f^{(n+1)}(c)}{n!}\cdot (x-c)^n}{-m\cdot (x-c)^{m-1}}\cdot \left(-(x-x_0)^{m}\right)\\ & =\frac{f^{(n+1)}(c)}{m\cdot n!}\cdot (x-c)^{n-m+1}\cdot (x-x_0)^{m},
\end{array}
$$
tal como queríamos demostrar.
</div>

## Ejemplo
<div class="example">
**Ejemplo**

Vamos a intentar aproximar la función $f(x)=\sin x$ para un $x$ próximo a $0$.

Recordemos que el polinomio de Taylor (de hecho, el de MacLaurin) de la función $f(x)$ de grado $n$ es el siguiente:
$$
P_n(x)=\sum_{i=0}^k \frac{(-1)^i x^{2i+1}}{(2i+1)!},
$$
con $k=\frac{n-2}{2}$, si $n$ es par y $k=\frac{n-1}{2}$, si $n$ es impar.

El problema que nos planteamos es el siguiente: dado $x$ y $e$ un error absoluto máximo que estamos dispuestos a cometer, calcular el valor de $P_n(x)$ tal que $|f(x)-P_n(x)=|\sin x-P_n(x)|\leq e$.

El primer paso es calcular el valor de $n$. Nos fijamos a partir de la expresión de $P_n(x)$ que si $n$ es par el grado del polinomio de MacLaurin tiene grado $n-1$ ya que la potencia más alta de $x$, $2k+1$ vale $2k+1=n-1$.

Supondremos que $n$ es par ya que tiene un término menos que si $n$ es impar y esto es una ventaja a la hora de computar $P_n(x)$. 
</div>

## Ejemplo
<div class="example">
El error cometido $R_n(x)$ usando el teorema anterior vale: (usaremos la fórmula de Lagrange)
$$
f(x)-P_n(x)=R_n(x)=\frac{f^{n+1}(c)}{(n+1)!}\cdot x^{n+1}.
$$
Dicho error se puede acotar por:
$$
|f(x)-P_n(x)|=|R_n(x)|=\left|\frac{f^{n+1}(c)}{(n+1)!}\cdot x^{n+1}\right|\leq \max_{c\in <0,x>}\left|f^{n+1}(c)\right|\cdot \frac{|x|^{n+1}}{(n+1)!}.
$$
Al ser $n$ par, $|f^{n+1}(c)|=|\cos c|$ ya que $n+1$ es impar y recordemos que cualquier derivada impar era $\pm \cos c$. Por tanto, podemos acotar $\displaystyle \max_{c\in <0,x>}\left|f^{n+1}(c)\right|$ por $1$:
$\displaystyle\max_{c\in <0,x>}\left|f^{n+1}(c)\right|\leq 1$ y la cota del error será:
$$
|f(x)-P_n(x)|=|R_n(x)|\leq  \frac{|x|^{n+1}}{(n+1)!}.
$$
La $n$ buscada debe verificar: $\frac{|x|^{n+1}}{(n+1)!}\leq e$.

Como para cualquier valor de $x$ el límite $\displaystyle\lim_{n\to\infty} \frac{|x|^{n+1}}{(n+1)!}=0$, seguro que existe una $n$ tal que $\frac{|x|^{n+1}}{(n+1)!}\leq e$.
</div>

## Ejemplo
<div class="example">
La función siguiente nos calcula la $n$ dado $x$ y $e$ en `python` asegurándose que $n$ es par:
```{python}
import math
def n(x,error):
 x=float(x)
 m=2
 while(abs(x)**(m+1)/math.factorial(m+1) >=error):
   m=m+1
 if(m % 2==1):
   m=m+1
 return(m)
```
El valor de $n$ para $x=0.5$ con un error máximo permitido de $0.0001$ será:
```{python}
n(0.5,0.0001)
```


</div>